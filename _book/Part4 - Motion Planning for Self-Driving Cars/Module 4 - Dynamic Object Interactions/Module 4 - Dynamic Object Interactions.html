
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Module 4 - Dynamic Object Interactions · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="../Module 5 - Principles of Behaviour Planning/Module 5 - Principles of Behaviour Planning.md" />
    
    
    <link rel="prev" href="../Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../../Part1 - Introduction to Self-Driving Cars/">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/">
            
                    
                    Part1: Introduction to Self-Driving Cars
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../../Part1 - Introduction to Self-Driving Cars/Module0-Welcome to the self-driving cars specialization/module0-welcome-to-the-self-driving-cars-specialization.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module0-Welcome to the self-driving cars specialization/module0-welcome-to-the-self-driving-cars-specialization.html">
            
                    
                    Module 0：Welcome to the self-driving cars specialization
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../../Part1 - Introduction to Self-Driving Cars/Module1-The Requirements for Autonomy/module1-the-requirements-for-autonomy.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module1-The Requirements for Autonomy/module1-the-requirements-for-autonomy.html">
            
                    
                    Module 1：The Requirements for Autonomy
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../../Part1 - Introduction to Self-Driving Cars/Module2-Self-Driving Hardware and Software Architectures/module2-self-driving-hardware-and-software-architectures.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module2-Self-Driving Hardware and Software Architectures/module2-self-driving-hardware-and-software-architectures.html">
            
                    
                    Module2：Self-Driving Hardware and Software Architectures
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="../../Part1 - Introduction to Self-Driving Cars/Module3-Safety Assurance for Autonomous Vehicles/module3-safety-assurance-for-autonomous-vehicles.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module3-Safety Assurance for Autonomous Vehicles/module3-safety-assurance-for-autonomous-vehicles.html">
            
                    
                    Module3：Safety Assurance for Autonomous Vehicles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="../../Part1 - Introduction to Self-Driving Cars/Module4-Vehicle Dynamic Modeling/module4-vehicle-dynamic-modeling.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module4-Vehicle Dynamic Modeling/module4-vehicle-dynamic-modeling.html">
            
                    
                    Module4：Vehicle Dynamic Modeling
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="../../Part1 - Introduction to Self-Driving Cars/Module5-Vehicle Longitudinal Control/module-5-vehicle-longitudinal-control.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module5-Vehicle Longitudinal Control/module-5-vehicle-longitudinal-control.html">
            
                    
                    Module 5：Vehicle Longitudinal Control
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="../../Part1 - Introduction to Self-Driving Cars/Module6-Vehicle Lateral Control/module-6-vehicle-lateral-control.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module6-Vehicle Lateral Control/module-6-vehicle-lateral-control.html">
            
                    
                    Module 6：Vehicle Lateral Control
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="../../Part1 - Introduction to Self-Driving Cars/Module7-Putting it all together/module-7-putting-it-all-together.html">
            
                <a href="../../Part1 - Introduction to Self-Driving Cars/Module7-Putting it all together/module-7-putting-it-all-together.html">
            
                    
                    Module 7：Putting it all together
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/">
            
                    
                    Part2：State Estimation and Localization for Self-Driving Cars
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 1 - Least Squares/Module 1 - Least Squares.html">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 1 - Least Squares/Module 1 - Least Squares.html">
            
                    
                    Module 1：Least Squares
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 2 - State Estimation - Linear and Nonlinear Kalman Filters/Module 2 - State Estimation - Linear and Nonlinear Kalman Filters.html">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 2 - State Estimation - Linear and Nonlinear Kalman Filters/Module 2 - State Estimation - Linear and Nonlinear Kalman Filters.html">
            
                    
                    Module 2 - State Estimation - Linear and Nonlinear Kalman Filters
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 3 - GNSS-INS Sensing for Pose Estimation/Module 3 - GNSS-INS Sensing for Pose Estimation.html">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 3 - GNSS-INS Sensing for Pose Estimation/Module 3 - GNSS-INS Sensing for Pose Estimation.html">
            
                    
                    Module 3 - GNSSINS Sensing for Pose Estimation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 4 - LIDAR Sensing/Module 4 - LIDAR Sensing.html">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 4 - LIDAR Sensing/Module 4 - LIDAR Sensing.html">
            
                    
                    Module 4 - LIDAR Sensing
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 5 - Putting It together - An Autonomous Vehicle State Estimator/Module 5 - Putting It together - An Autonomous Vehicle State Estimator.html">
            
                <a href="../../Part2 - State Estimation and Localization for Self-Driving Cars/Module 5 - Putting It together - An Autonomous Vehicle State Estimator/Module 5 - Putting It together - An Autonomous Vehicle State Estimator.html">
            
                    
                    Module 5 - Putting It together - An Autonomous Vehicle State Estimator
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../Part3 - Visual Perception for Self-Driving Cars/">
            
                <a href="../../Part3 - Visual Perception for Self-Driving Cars/">
            
                    
                    Part3：Visual Perception for Self-Driving Cars
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../">
            
                <a href="../">
            
                    
                    Part4：Motion Planning for Self-Driving Cars
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../Module 1 - The Planning Problem/Module 1 - The Planning Problem.html">
            
                <a href="../Module 1 - The Planning Problem/Module 1 - The Planning Problem.html">
            
                    
                    Module 1 - The Planning Problem
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../Module 2 - Mapping for Planning/Module 2 - Mapping for Planning.html">
            
                <a href="../Module 2 - Mapping for Planning/Module 2 - Mapping for Planning.html">
            
                    
                    Module 2 - Mapping for Planning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.html">
            
                <a href="../Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.html">
            
                    
                    Module 3 - Mission Planning in Driving Environments
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.5.4" data-path="Module 4 - Dynamic Object Interactions.html">
            
                <a href="Module 4 - Dynamic Object Interactions.html">
            
                    
                    Module 4 - Dynamic Object Interactions
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.5" data-path="../Module 5 - Principles of Behaviour Planning/Module 5 - Principles of Behaviour Planning.md">
            
                <span>
            
                    
                    Module 5 - Principles of Behaviour Planning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.6" data-path="../Module 6 - Reactive Planning in Static Environments/Module 6 - Reactive Planning in Static Environments.md">
            
                <span>
            
                    
                    Module 6 - Reactive Planning in Static Environments
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.7" data-path="../Module 7 - Putting it all together - Smooth Local Planning/Module 7 - Putting it all together - Smooth Local Planning.md">
            
                <span>
            
                    
                    Module 7 - Putting it all together - Smooth Local Planning
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >Module 4 - Dynamic Object Interactions</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="module-4---dynamic-object-interactions">Module 4 - Dynamic Object Interactions</h1>
<h2 id="learning-objects">Learning Objects</h2>
<ul>
<li>Recall the different types of <strong>motion prediction assumptions</strong>, and the differences between them.</li>
<li>Understand how map knowledge can be used for prediction.</li>
<li>Understand how multi-hypothesis prediction can be used to predict multiple behaviours.</li>
<li>Compute Time-to-Collision (TTC) through estimation and simulation methods.</li>
</ul>
<hr>
<h2 id="lesson-1-motion-prediction">Lesson 1: Motion Prediction</h2>
<blockquote>
<ul>
<li>Define the motion prediction problem for dynamic objects and its importance to planning</li>
<li>Identify the requirements for accurate motion prediction</li>
<li>Perform predictions with the Constant Velocity Prediction Model</li>
</ul>
</blockquote>
<p>Hi everyone, and welcome to Module Four of our Motion Planning course. This week, we will discuss methods used within the motion planner, to handle interactions between dynamic objects and the ego vehicle. We will start this week, by looking at the prediction of dynamic object motion. We will then go on to understanding how we are able to use the dynamic object predictions, in order to <strong>calculate the time to collision</strong> between the ego vehicle and other dynamic objects. </p>
<p>In this lesson, we will define motion prediction for dynamic objects and identify the importance of such predictions in the greater path planning problem. We&apos;ll describe the requirements to accurately and safely predict the motion of dynamic objects, and explore the challenges inherent in motion prediction. Finally, we&apos;ll perform our first predictions with the constant velocity prediction model. Let&apos;s get started. </p>
<hr>
<h3 id="1-motion-prediction---definition">1. Motion Prediction - Definition</h3>
<blockquote>
<ul>
<li>Motion prediction of the dynamic object&#x2019;s attempts to estimate the future position, heading and velocity</li>
<li>Important as it allows:<ul>
<li>Planning a set of maneuvers to correctly interact with dynamic objects</li>
<li>Avoid collisions on a planned trajectory</li>
</ul>
</li>
</ul>
</blockquote>
<p>Motion prediction attempts to estimate the future positions, headings, and velocities of all dynamic objects in the environment over some finite horizon. This is crucially important for the motion planning problem, as it allows us to plan future actions and maneuvers for the autonomous vehicle, based on the expected motions of other objects. The predicted paths also allow us to make sure that the path which the ego vehicle plans to execute, will not collide with any future objects at a future time. </p>
<hr>
<h3 id="2-requirements-for-motion-prediction-models">2. Requirements for Motion Prediction Models**</h3>
<p>In order to be able to predict the motion of moving objects, we must have access to some information about the environment around us. Especially as it relates to dynamic objects. For all dynamic objects, we must first know the class of the object. This information is vitally important as most prediction models have different algorithmic approaches to vehicles as opposed to pedestrians. Next, we need to have information regarding the dynamic objects current state, its position, and velocity in the environment. Represented here by a red vector with the vector origin equal to the vehicle position, the vector magnitude equal to its speed, and the vector&apos;s direction equal to its current heading or direction of travel. Without this minimal information, no predictions can be made about the dynamic objects future states. Finally, there are many other pieces of information which although not required to make a prediction, can greatly improve the accuracy of the predictions. </p>
<p><img src="assets/1564899493928.png" alt="1564899493928"></p>
<p>While this list that we&apos;ll present is not exhaustive, it does demonstrate some of the major sources of additional information to improve predictions. First is the history of the dynamic vehicle state or the vehicle track as it moves through the environment. This can be extremely useful. You&apos;ve learned how to generate vehicle tracks from object detections in course three. We can use this information to get a better idea of how the object is maneuvering through the environment. </p>
<p>As we can see in our example, we can see the vehicle state history shown as black arrow, with the position heading and speed represented as before. A high definition roadmap can also be used as an additional information source, to determine future behavior of dynamic objects. As will be discussed further in this module, vehicles tend to follow their respective lanes while driving down the road. This can provide strong cues to improve prediction accuracy. An image of the dynamic object in its current state can also be a useful source of information that can improve predictions. This is true for both vehicles and pedestrians. For vehicles, the image can provide information concerning the current indicator light or brake lights states, for example. Similarly, images of pedestrians can serve to show the current orientation of the person, which can help predict a future direction of travel, even if the pedestrian is currently stationary. </p>
<hr>
<h3 id="3-simplification-of-motion-prediction">3. Simplification of Motion Prediction</h3>
<h4 id="31-cars">3.1 Cars</h4>
<p><strong>Although the complexities of the task of motion prediction are quite large, there are several assumptions we can use to simplify the problem.</strong> We will start by looking at simplifications for vehicles and then move on to pedestrians. These are the two main categories we&apos;ll discuss, but you can imagine similar approaches needed for cyclists and animals such as dear, rodents, or even kangaroos. </p>
<p><img src="assets/1564901850006.png" alt="1564901850006"></p>
<p>The first class of assumptions we rely on, is that vehicles must follow a set of physical constraints governing their movement. As we saw in course one when we were discussing Vehicle Kinematics and Dynamics. These very same vehicle dynamics can be applied to other vehicles in the environment to predict their motion. We refer to this type of prediction as a physics-based prediction. </p>
<p>The second class of assumptions that can be used are that almost all motions by a vehicle on the road, are made up of a finite set of maneuvers in a restricted domain in the environment. In this case, we assume that vehicles which are on the road will stay on the road and follow the driving rules. For example, they will most likely stay in their lane unless indicating otherwise and stop at regulatory elements requiring stops. They are unlikely to drive over sidewalks or lawns or through obstacles. We refer to this type of assumption as maneuver-based. </p>
<p>Finally, the third class makes the same assumptions as the maneuver-based assumptions. However, instead of only evaluating each vehicle independently, we can also incorporate the assumption that the dynamic objects will react and interact with each other. An example of this type of prediction, is during a merge by a vehicle into an adjacent lane. Often, the vehicle in the destination lane will slow down to make more room for the incoming vehicle to maintain a safe following distance. These types of assumptions are referred to as interaction-aware assumptions. </p>
<h4 id="32-pedestrians">3.2 Pedestrians</h4>
<p>For pedestrians, the same three categories can be used to summarize the assumptions we can make. In terms of physics-based assumptions, pedestrians tend to have a low top speed but can change their direction of motion and speed very quickly. This makes pedestrians quite challenging to predict reliably using purely physics-based assumptions, but the range of positions a pedestrian can reach in a short time frame is limited. For maneuver based assumptions, pedestrians tend not to interact directly with vehicles. As they primarily use sidewalks or other pedestrian exclusive zones when traveling. When entering the drivable areas of the environment such that they might come into contact with vehicles, they primarily use pedestrian crossings. </p>
<p><img src="assets/1564902311390.png" alt="1564902311390"></p>
<p>Although restricting pedestrian motion to these regions is a reasonable assumption, it is not a hard constraint and the unpredictability of pedestrians requires maintaining multiple possible hypotheses about their future actions. Finally, pedestrians ultimately have the right of way and it is the self-driving cars duty to stop when necessary. Inattentive pedestrians may wander into a roadway without warning, but will often stop when threatened by an oncoming vehicle. These types of interactive assumptions can also be incorporated into motion prediction for pedestrians. </p>
<hr>
<h3 id="4-constant-velocity-prediction-model">4. Constant Velocity Prediction Model</h3>
<p>Now that we have a better understanding of motion prediction, let&apos;s have a look at a simple computationally efficient algorithm, that can be equally applied to both pedestrians and vehicles. </p>
<p>This algorithm makes only one extreme assumption regarding the motion of the dynamic object. <strong>All dynamic objects will maintain their current velocity both in terms of magnitude as well as heading.</strong> Understanding this, let&apos;s now look at the algorithmic implementation of this simple constant velocity model. </p>
<p><img src="assets/1564902833713.png" alt="1564902833713"></p>
<p>The algorithm takes three basic inputs $t$, the prediction horizon or the amount of time to predict the object&apos;s location into the future, $dt$ , the update rate or path simulation frequency, that is the amount of time between state predictions, and $x_{obj}$, the current object&apos;s state which includes the position and velocity of the dynamic object. This algorithm iterates from the current time zero until the end of the horizon $t$ in increments of $dt$ . As we saw in the trajectory rollout algorithm in the previous videos, updating the path with constant velocity model. The output of this algorithm is a list of predicted objects states, positions, and velocities for every time step in the prediction horizon. To see how well these predictions perform, let&apos;s look at a quick example. </p>
<hr>
<h3 id="5-constant-velocity-prediction-model---example">5. Constant Velocity Prediction Model - Example</h3>
<p>We&apos;ll use a three second horizon with a one second update step and the current vehicles state as indicated by the red arrow in this figure. As expected, the predicted locations of the vehicle move in a constant direction with a fixed step size which corresponds very nicely with this straight line segment, with a constant speed limit. Simply put, this is because the constant velocity assumption is valid for this segment of roadway. </p>
<p><img src="assets/1564903371753.png" alt="1564903371753"></p>
<p>Where the constant velocity estimate fails, however, is everywhere else. While this algorithm weakly falls into the category of physics-based assumptions, it fails to capture the full complexity of vehicle dynamics models, or even the ability of a vehicle to accelerate or decelerate or apply a steering command other than zero. Another large flaw of the constant velocity assumption, is that it fails to account for vehicles tendency to follow changes in the road shape. At every point in this curved roadway example, the constant velocity model predicts the path will continue into the oncoming lane. These predictions are wholly unsuited to behavior planning. </p>
<p><img src="assets/1564903408844.png" alt="1564903408844"></p>
<p>Similarly, the constant velocity prediction fails to account for road signs to make velocity adjustments. Vehicles approaching stop signs tend to slow down and vehicles leaving a stop line tend to accelerate. The assumption which this algorithm makes is quite strong and does not apply for most cases that dynamic objects may be observed in. The key challenge to motion prediction is really to select the most likely inputs, to a vehicle or pedestrian model given what information is available. Nonetheless, the constant velocity model is an excellent starting point and helps define the concept of motion prediction clearly. It relies on a minimum of information about the dynamic object, to form its predictions and can be used wherever additional cues are completely unavailable. </p>
<hr>
<h3 id="6-summary">6. Summary</h3>
<blockquote>
<ul>
<li>Identified motion prediction and its Importance </li>
<li>Requirements for motion prediction</li>
<li>Assumption for Simplifying the problem in the case of <ul>
<li>Vehicles</li>
<li>Pedestrians</li>
</ul>
</li>
<li>Simple Constant Velocity Prediction Model</li>
<li>Issues with Simple Constant Velocity Prediction Model</li>
</ul>
</blockquote>
<p>Let&apos;s summarize. In this lesson, we learned about the task of motion prediction for dynamic objects and its importance to autonomous driving. We then defined minimal and optional information requirements to create effective motion prediction algorithms for both vehicles and pedestrians. We then looked at a simple constant velocity algorithm for predicting the future location of objects and identified many of its limitations. In the next video, we will look at the methods to enhance our motion predictions, through the use of high-definition roadmaps. We&apos;ll see you then.</p>
<hr>
<h2 id="lesson-2-map-aware-motion-prediction">Lesson 2: Map-Aware Motion Prediction</h2>
<h3 id="learning-objectives">Learning Objectives</h3>
<blockquote>
<ul>
<li>Describing a set of assumptions made by map-aware algorithms to improve motion prediction</li>
<li>Define a lane follow method to improve positional prediction<ul>
<li>Identify strategies to handle multiple future lane choices</li>
</ul>
</li>
<li>Determine methods for velocity modulation around regulatory elements</li>
<li>Identify issues and short-falls with the map-aware assumptions</li>
</ul>
</blockquote>
<p>Welcome to the second lesson in our module on Dynamic Object Interaction. In this video, we will be extending the topic of motion prediction of dynamic objects, to include information available from the HD road map. To begin, we will discuss the different assumptions relied on by map-aware where algorithms, for motion prediction, To keep the task simple and efficient. Then we will look at applying a lane following prediction approach, to improve position prediction components. Next, we&apos;ll explore map-based prediction when multiple lane options are available. Then we&apos;ll explore a velocity prediction around regulatory elements. Finally, we&apos;ll discuss some of the issues in short-falls of map-aware predictions that revolve around assumptions made regarding dynamic objects. So let&apos;s get started. </p>
<hr>
<h3 id="1-assumptions-to-improve-prediction">1. Assumptions to Improve Prediction</h3>
<p>In the previous video, we explored constant velocity motion prediction, which worked well only in a very limited number of scenarios. Map-aware algorithms make two broad categories of assumptions to improve the motion predictions particularly for vehicles. <strong>Position-based assumptions to improve the position component of the vehicle state, and velocity-based assumptions to improve the velocity component.</strong> </p>
<p>The first assumption made to improve the position component of the prediction, is that vehicles driving down a given lane usually follow that lane. Returning to our simple example scenario, if we have a vehicle on a curved roadway, the vehicle will most likely turn along with the roadway. The second assumption that can be made is that a drive lane change or direction prediction, can be made based on the state of the indicator light of the vehicle. If such a detection has been made by the perception stack for a vehicle, it is possible to switch the prediction to account for this additional information. </p>
<p><img src="assets/1564906508974.png" alt="1564906508974"></p>
<p>Velocity-based assumptions are used to improve the velocity prediction of a dynamic object. All vehicles on the road are affected by road geometry. Thus, it is useful to assume that as a vehicle approaches a turn with significant curvature, the vehicle is likely to slow down to avoid exceeding its lateral acceleration limits. Finally, velocity prediction can be greatly enhanced if we also consider a regulatory elements, which the dynamic object may encounter. For example, if there is a stop sign at a close distance in front of a dynamic object, it is safe to assume that the vehicle will execute a decelerate to stop maneuver, resulting in a lower velocity over time. </p>
<p>Well this is not a complete set of all assumptions that can be made to improve motion prediction using HD road maps, they are sufficient to illustrate the diversity of contextual information available to improve our predictions. Further, it is important to understand that the more constraints or assumptions that are added to a prediction model, the less generalizable it can be to all traffic scenarios. In fact, by the end of this lesson, we will see cases where even these generic assumptions can be overly constraining. </p>
<hr>
<h3 id="2-improvement-of-position-estimation">2. Improvement of Position Estimation</h3>
<p>Let&apos;s now incorporate each of these map-based assumptions into our motion prediction methods. For roadways with natural curvature, we make the assumption that a vehicle which is on a drive lane will likely follow that drive lane through the curve. Our motion predictions can be updated then by using the center line of the mainland map as the predicted path of the vehicle, instead of the straight line path generated by constant velocity predictions. </p>
<p><img src="assets/1564909183219.png" alt="1564909183219"></p>
<p>Recall the lane that map definition from module two of this course which provides left, and right lane boundaries for every lane on the road from which there can be a center line to construct it. The center line of a lane lit is defined as a set of points making up a polyline that is equally spaced from both lane boundaries. While minor deviations from the exact center line can be expected, the center line can act as a good motion prediction approximation. This is a major step forward over constant velocity predictions on any roadway with curvature. </p>
<hr>
<h3 id="3-improvement-of-position-estimation">3. Improvement of Position Estimation</h3>
<p>However, by restricting path predictions to the center line of any given lane lit, will result in two major issues. The first is that during normal driving, drivers routinely change lanes. So as mentioned earlier, such maneuver may be predicted based on indicator light perception. Although not all lean changes by human drivers are preceded by an indication. </p>
<p>The second problem that arises is that it is regularly the case, that there is more than one center line to choose from. Such as in the case of an intersection. For example, at this simple T junction, it is possible for the vehicle to turn either left or right. This leads us to the need to consider multiple hypotheses based on likely behaviors of the other agents in the scene. Again, we have two options: we can identify the most likely behavior using objects state, appearance, and track information, and then construct a prediction based on the most likely behavior, or we can construct a prediction for the most likely behaviors and associate a probability that the agents will follow a particular path based on the state appearance and track information. The second approach is a slight generalization of the first. So we will focus our attention on it. We refer to this as multi hypothesis prediction. In the case of multi-hypothesis prediction approaches, each nominal behavior of a vehicle based on the full range of possibilities available to it at its current location in the HD road map is considered. For the three-way intersection example, we can include three possibilities: turn left, turn right, or stay stationary. Based on corroborating evidence such as indicators signals, position to the left or right of the center line, and the state of the vehicle at the intersection. It is possible to evaluate each of the three hypotheses in terms of the likelihood the agent will execute each of them within the prediction horizon. These probabilities can be hard to quantify exactly. So can either be learned from training data of many vehicles proceeding through similar intersections, or can be engineered and refined from real-world testing. Such approaches traditionally provide more ambiguous information to the behavior planner, requiring this next stage of the planning process, to consider multiple scenarios simultaneously, and to handle the probabilistic representation of belief. However, if handled correctly, this approach can also be significantly safer, enabling defensive driving strategies, and rapid re-planning if probabilities shift based on new information. This approach also has an advantage of being able to adapt to human-based driving errors. Such as forgetting to signal when changing lanes. Now that we understand how a road map can be used to improve the positional component of the predicted trajectories, let us now dive into the velocity component. The first improvement in this area is based on the known road geometry or curvature, and the prediction of how other vehicles will react to it. All vehicles no matter their making model, will reduce their velocity as they enter sharp curves or execute turns. We can use an expected maximum lateral acceleration, usually in the range of 0.5 to one meter per second squared, to improve velocity estimation along curves. The second and more significant improvement is to incorporate regulatory elements to improve velocity estimation. Given the anticipated path of the vehicle, any roadway elements such as stop signs, yield signs, speed limit changes or traffic lights, can all inform the velocity prediction. In the case of traffic lights the lights state is also required. In each case a stop location can be predicted based on the regulatory element line, as defined in the road map. Then a smooth deceleration can be applied to the vehicle velocity prediction along its path. In fact, given a HD road map, it is possible to preprocess the map for nominal trajectories along each roadway, and to define lanelet specific multi-hypothesis priors, based on nominal driving behavior. This serves both as guidance for the ego vehicle in planning its behaviors and trajectories, and also in terms of refining the motion predictions for other agents. Of course obstructions in the lane ahead of a vehicle precedence of arrival information at intersections and lead vehicles in the lane, can all be integrated to improve predictions for other vehicles. Given the complexity of making decisions for a single self-driving car, there is a limit to how many variables and how much depth of information in logic can be used, to improve motion prediction. There is also a limit to how much we can rely on assumptions about expected dynamic object behavior, to predict future actions. Dynamic objects do not always behave according to the nominal behaviors expected of the drivers. They do not exactly follow the center line, do not drive at the speed limit, accelerate and decelerate at different rates for example. Further, they may react to information not yet available to the prediction system, such as a potholes in the road ahead or a bouncing ball. They may simply not observe a regulatory element as occurs when a vehicle accidentally runs a red light. All these variations must be accounted for which can be done to some extent with the multi-hypothesis approach. The best approach is therefore to track the evolution of beliefs over the set of hypotheses, and to update based on evidence from the perception stack at every time step. There is a great deal of complexity embedded in these methods, and we encourage you to explore some of the challenging issues associated with motion prediction for self-driving cars, by digging into the references included in the supplementary materials. This concludes our discussion of motion prediction. In today&apos;s lesson, we have described a set of assumptions for map-aware algorithms, to improve motion prediction of vehicles on drive lanes, defined position and velocity-based methods to improve motion prediction, described multi-hypothesis prediction as a way to maintain multiple beliefs about another vehicles future actions, and finally identified some of the issues with exclusively relying on map-aware motion prediction. I hope you will join us next time where we will see how to use our predicted paths, to calculate a time to collision, between pairs of dynamic objects. See you there.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="../Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.html" class="navigation navigation-prev " aria-label="Previous page: Module 3 - Mission Planning in Driving Environments">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="../Module 5 - Principles of Behaviour Planning/Module 5 - Principles of Behaviour Planning.md" class="navigation navigation-next " aria-label="Next page: Module 5 - Principles of Behaviour Planning">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Module 4 - Dynamic Object Interactions","level":"1.5.4","depth":2,"next":{"title":"Module 5 - Principles of Behaviour Planning","level":"1.5.5","depth":2,"path":"Part4 - Motion Planning for Self-Driving Cars/Module 5 - Principles of Behaviour Planning/Module 5 - Principles of Behaviour Planning.md","ref":"Part4 - Motion Planning for Self-Driving Cars/Module 5 - Principles of Behaviour Planning/Module 5 - Principles of Behaviour Planning.md","articles":[]},"previous":{"title":"Module 3 - Mission Planning in Driving Environments","level":"1.5.3","depth":2,"path":"Part4 - Motion Planning for Self-Driving Cars/Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.md","ref":"Part4 - Motion Planning for Self-Driving Cars/Module 3 - Mission Planning in Driving Environments/Module 3 - Mission Planning in Driving Environments.md","articles":[]},"dir":"ltr"},"config":{"plugins":["mathjax","livereload"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"mathjax":{"forceSVG":false,"version":"2.6-latest"},"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","pdf":{"pageBreaksBefore":"/","headerTemplate":null,"paperSize":"a4","margin":{"right":62,"left":62,"top":36,"bottom":36},"fontSize":12,"fontFamily":"Arial","footerTemplate":null,"chapterMark":"pagebreak","pageNumbers":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"links":{"sidebar":{},"sharing":{"google":null,"facebook":null,"twitter":null,"weibo":null,"all":null}},"gitbook":"*","description":null,"extension":null},"file":{"path":"Part4 - Motion Planning for Self-Driving Cars/Module 4 - Dynamic Object Interactions/Module 4 - Dynamic Object Interactions.md","mtime":"2019-08-04T08:59:44.322Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-08-05T02:51:43.011Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

